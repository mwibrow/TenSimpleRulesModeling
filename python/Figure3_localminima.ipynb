{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3., 0., 0., 0., 0., 0., 0., 0., 7.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3])\n",
    "\n",
    "def insert(arr, index, value):\n",
    "    if index > len(arr):\n",
    "        new_arr = np.zeros((index + 1,))\n",
    "        new_arr[:len(arr)] = arr\n",
    "        arr = new_arr\n",
    "    arr[index] = value\n",
    "    return arr\n",
    "        \n",
    "insert(a, 10, 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  5, 10, 15, 20, 25, 30, 35, 40, 45, 50])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(([1], np.arange(5, 50 + 5, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 4, 5, 6, 2, 3, 4, 5, 6, 2, 3, 4, 5, 6, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tile(np.arange(2, 7), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a range of learning rates to test\n",
    "alphas = np.arange(0.05, 1 + 0.05, 0.05)\n",
    "# define a range of softmax parameters to test\n",
    "betas = np.concatenate(([1], np.arange(5, 50 + 5, 5)))\n",
    "# define a range of WM reliance to test\n",
    "rhos = np.arange(0, 1 + 0.05, 0.05)\n",
    "# define a range of capacities to test\n",
    "Ks = np.arange(2, 6 + 1)\n",
    "\n",
    "# for a finer grid:\n",
    "# alphas = [.06:.01:.5];%[0.05:.05:1];\n",
    "# betas = [1 4:2:20];%[1 5:5:50];\n",
    "# rhos = [.5:.01:.98];%[0:.05:1];\n",
    "\n",
    "\n",
    "# define simulation parameters\n",
    "realalpha = .1\n",
    "realbeta = 10\n",
    "realrho = .9\n",
    "realK = 4\n",
    "## simulate the RLWM task\n",
    "\n",
    "b = 0\n",
    "t = 0\n",
    "update = np.zeros(dtype=int)\n",
    "\n",
    "\n",
    "Reps = 3\n",
    "Trials = 15\n",
    "nsMin = 2\n",
    "nsMax = 6\n",
    "\n",
    "alloc = Reps * Trials * (nsMax - nsMin + 1) / 2 * ( 2 * nsMax + (nsMax - nsMin))\n",
    "update = np.zeros((1, alloc))\n",
    "choice = np.zeros((1, alloc))\n",
    "\n",
    "for rep in range(Reps): # three repetitions of each set size\n",
    "    for ns in range(nsMin, nsMax + 1): # block of set size ns\n",
    "        \n",
    "        b = b + 1\n",
    "        update[t] = 1\n",
    "        # initialize WM mixture weight\n",
    "        w = realrho * np.min(1, realK / ns)\n",
    "        # initialize RL and WM agents\n",
    "        Q = .5 + np.zeros(ns, 3)\n",
    "        WM = .5 + np.zeros(ns, 3)\n",
    "        # define a sequence of trials with 15 iterations of each stimulus\n",
    "        trials = np.tile(np.array(1, ns + 1, 1), Trials)\n",
    "        # loop over trials\n",
    "        for s in trials:\n",
    "            t = t + 1\n",
    "            # RL policy\n",
    "            softmax1 = np.exp(realbeta * Q[s - 1, :]) / np.sum(np.exp(realbeta * Q[s - 1, :]))\n",
    "            # WM policy\n",
    "            softmax2 = np.exp(50 * WM[s - 1, :]) / np.sum(np.exp(50 * WM[s - 1, :]))\n",
    "            # mixture policy\n",
    "            pr = (1 - w) *softmax1 + w * softmax2\n",
    "            # action choice\n",
    "            r = rand()\n",
    "            if r < pr[0]:\n",
    "                choice[t] = 1\n",
    "            elif r < pr[0] + pr[1]\n",
    "                choice[t] = 2 \n",
    "            else\n",
    "                choice[t] = 3\n",
    "           \n",
    "            # reward correct action (arbitrarily defined here)\n",
    "            rew[t] = choice[t] == (rem(s,3)+1);\n",
    "            # update RL and WM agents\n",
    "            Q(s,choice(t))=Q(s,choice(t))+realalpha*(rew(t)-Q(s,choice(t)));\n",
    "            WM(s,choice(t))=rew(t);\n",
    "            # store information\n",
    "            stim(t)=s;\n",
    "            setsize(t)=ns;\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
